---
title: "01. Introducci√≥n y Arquitectura de Snowflake"
---

## Introducci√≥n y Arquitectura de Snowflake

## Tabla de Contenidos

- [Introducci√≥n y Arquitectura de Snowflake](#introducci√≥n-y-arquitectura-de-snowflake)
- [Tabla de Contenidos](#tabla-de-contenidos)
- [Conceptos b√°sicos e introducci√≥n](#conceptos-b√°sicos-e-introducci√≥n)
  - [¬øQue es Snowflake?](#que-es-snowflake)
  - [¬øPara qu√© se utiliza Snowflake?](#para-qu√©-se-utiliza-snowflake)
  - [Caracter√≠sticas principales](#caracter√≠sticas-principales)
  - [Caso pr√°ctico: Creaci√≥n de una cuenta en Snowflake](#caso-pr√°ctico-creaci√≥n-de-una-cuenta-en-snowflake)
    - [Objetivos del caso pr√°ctico](#objetivos-del-caso-pr√°ctico)
- [Arquitectura de Snowflake](#arquitectura-de-snowflake)
  - [Arquitectura de tres capas](#arquitectura-de-tres-capas)
    - [1. Service Layer (Cloud Services)](#1-service-layer-cloud-services)
    - [2. Compute Layer (Query Processing)](#2-compute-layer-query-processing)
    - [3. Storage Layer (Database Storage)](#3-storage-layer-database-storage)
- [Comparaci√≥n entre bases de datos por filas y por columnas](#comparaci√≥n-entre-bases-de-datos-por-filas-y-por-columnas)
  - [Arquitectura Multi-Cluster, Shared-Disk](#arquitectura-multi-cluster-shared-disk)
    - [Modelo de almacenamiento centralizado](#modelo-de-almacenamiento-centralizado)
    - [Procesamiento distribuido mediante Virtual Warehouses](#procesamiento-distribuido-mediante-virtual-warehouses)
    - [Escalabilidad y concurrencia optimizadas](#escalabilidad-y-concurrencia-optimizadas)
- [Conexi√≥n a Snowflake](#conexi√≥n-a-snowflake)
  - [Ecosistema de Snowflake](#ecosistema-de-snowflake)
  - [Snowsight: The Snowflake web interface](#snowsight-the-snowflake-web-interface)
  - [SnowSQL (CLI Client)](#snowsql-cli-client)
- [Caso pr√°ctico: Uso de SnowSQL para la gesti√≥n de datos](#caso-pr√°ctico-uso-de-snowsql-para-la-gesti√≥n-de-datos)
  - [Objetivos del caso pr√°ctico](#objetivos-del-caso-pr√°ctico-1)
  - [Snowflake Extension for Visual Studio Code](#snowflake-extension-for-visual-studio-code)
    - [Caso pr√°ctico: Conexi√≥n de Snowflake con VSC](#caso-pr√°ctico-conexi√≥n-de-snowflake-con-vsc)
- [Virtual Warehouse](#virtual-warehouse)
  - [Funciones del Warehouse](#funciones-del-warehouse)
  - [Sintaxis para la gesti√≥n de un Warehouse](#sintaxis-para-la-gesti√≥n-de-un-warehouse)
    - [Creaci√≥n de un Warehouse](#creaci√≥n-de-un-warehouse)
    - [Ejemplo de configuraci√≥n avanzada](#ejemplo-de-configuraci√≥n-avanzada)
    - [Modificaci√≥n y gesti√≥n de un Warehouse](#modificaci√≥n-y-gesti√≥n-de-un-warehouse)
    - [Eliminaci√≥n de un Warehouse](#eliminaci√≥n-de-un-warehouse)
  - [Tipos de Virtual Warehouse](#tipos-de-virtual-warehouse)
    - [Ejemplo: Crear un warehouse optimizado para Snowpark](#ejemplo-crear-un-warehouse-optimizado-para-snowpark)
  - [Warehouse Size](#warehouse-size)
    - [Configuraci√≥n de AUTO_SUSPEND](#configuraci√≥n-de-auto_suspend)
    - [Configuraci√≥n de AUTO_RESUME](#configuraci√≥n-de-auto_resume)
  - [Escalabilidad Autom√°tica con Multi-cluster](#escalabilidad-autom√°tica-con-multi-cluster)
    - [¬øC√≥mo funciona?](#c√≥mo-funciona)
    - [Ejemplo de creaci√≥n de un Warehouse con escalabilidad autom√°tica:](#ejemplo-de-creaci√≥n-de-un-warehouse-con-escalabilidad-autom√°tica)
    - [Pol√≠tica de Escalado](#pol√≠tica-de-escalado)
  - [Impacto del Tama√±o del Warehouse y Recomendaciones por Tipo de Carga](#impacto-del-tama√±o-del-warehouse-y-recomendaciones-por-tipo-de-carga)
    - [Cargas de datos (ETL)](#cargas-de-datos-etl)
    - [Consultas y dashboards (BI)](#consultas-y-dashboards-bi)
    - [Desarrollo y pruebas](#desarrollo-y-pruebas)
    - [Ciencia de datos / Snowpark](#ciencia-de-datos--snowpark)
  - [Cach√© en el Warehouse](#cach√©-en-el-warehouse)
  - [Caso pr√°ctico: Creaci√≥n de Warehouses seg√∫n necesidades de cada rol](#caso-pr√°ctico-creaci√≥n-de-warehouses-seg√∫n-necesidades-de-cada-rol)
    - [Objetivos del caso pr√°ctico](#objetivos-del-caso-pr√°ctico-2)
- [Zero-Copy Cloning y Data Sharing en Snowflake](#zero-copy-cloning-y-data-sharing-en-snowflake)
  - [¬øQu√© es Zero-Copy Cloning?](#qu√©-es-zero-copy-cloning)
    - [Ventajas](#ventajas)
    - [Sintaxis para crear un clon:](#sintaxis-para-crear-un-clon)
- [Data Sharing en Snowflake](#data-sharing-en-snowflake)
  - [¬øQu√© es Data Sharing?](#qu√©-es-data-sharing)
  - [Arquitectura del Data Sharing](#arquitectura-del-data-sharing)
  - [M√©todos de Compartici√≥n de Datos](#m√©todos-de-compartici√≥n-de-datos)
  - [Pasos para crear un Data Share](#pasos-para-crear-un-data-share)
  - [Uso de Reader Accounts](#uso-de-reader-accounts)
    - [¬øQu√© es un Reader Account?](#qu√©-es-un-reader-account)
    - [Crear una cuenta Reader:](#crear-una-cuenta-reader)
  - [Acceso a los datos compartidos desde la cuenta consumidora](#acceso-a-los-datos-compartidos-desde-la-cuenta-consumidora)
  - [Beneficios del Data Sharing](#beneficios-del-data-sharing)
  - [Caso pr√°ctico: Creaci√≥n y uso de Shares en Snowflake](#caso-pr√°ctico-creaci√≥n-y-uso-de-shares-en-snowflake)
    - [Objetivos del caso pr√°ctico](#objetivos-del-caso-pr√°ctico-3)
- [Time Travel](#time-travel)
  - [¬øQu√© es Time Travel?](#qu√©-es-time-travel)
    - [Comandos para recuperar datos:](#comandos-para-recuperar-datos)
    - [Clonado con Time Travel](#clonado-con-time-travel)
- [Fail-safe en Snowflake](#fail-safe-en-snowflake)
  - [¬øQu√© es Fail-safe?](#qu√©-es-fail-safe)
  - [Diferencias entre Time Travel y Fail-safe](#diferencias-entre-time-travel-y-fail-safe)
- [Snowflake Caching](#snowflake-caching)
  - [1. Query Result Cache](#1-query-result-cache)
  - [2. Metadata Cache](#2-metadata-cache)
  - [3. Virtual Warehouse Local Disk Cache](#3-virtual-warehouse-local-disk-cache)


---

## Conceptos b√°sicos e introducci√≥n

### ¬øQue es Snowflake?

Snowflake es una plataforma en la nube dise√±ada para el almacenamiento y an√°lisis de datos. Es una soluci√≥n:  
- **Escalable**  
- **Segura**  
- **Eficiente**  

A diferencia de bases de datos convencionales, Snowflake es un servicio totalmente administrado, permitiendo a las organizaciones enfocarse en el an√°lisis en lugar de la administraci√≥n de infraestructura.

### ¬øPara qu√© se utiliza Snowflake?
Snowflake es ampliamente utilizado en diversos sectores para satisfacer necesidades de almacenamiento y an√°lisis de datos.

- **Data Warehousing**  
- **Business Intelligence (BI) y Anal√≠tica**  
- **Integraci√≥n de Datos (ETL/ELT)**  
- **Machine Learning e Inteligencia Artificial**  
- **Big Data y procesamiento en tiempo real**  
- **Gobernanza y seguridad de datos**  

### Caracter√≠sticas principales
Snowflake ofrece una serie de caracter√≠sticas clave que lo diferencian de otras soluciones de almacenamiento y an√°lisis de datos

- **Arquitectura de almacenamiento y computaci√≥n separada**  
- **Almacenamiento en la nube**  
- **Escalabilidad autom√°tica**  
- **Soporte para datos estructurados y semiestructurados**  
- **Concurrencia y aislamiento de cargas de trabajo**  
- **Modelo de pago por uso**  

### Caso pr√°ctico: Creaci√≥n de una cuenta en Snowflake  

Como primer caso pr√°ctico del curso, crearemos una cuenta en Snowflake desde cero. Este ejercicio permitir√° familiarizarse con la plataforma y explorar sus capacidades desde el primer acceso.  

#### Objetivos del caso pr√°ctico  
- Aprender a registrarse en **Snowflake** de forma gratuita.  
- Configurar los primeros ajustes de la cuenta.  
- Acceder a la interfaz web **Snowsight** y conocer sus funcionalidades b√°sicas.  

Para comenzar, sigue las instrucciones detalladas en el siguiente documento:  

üìÑ **[Caso Pr√°ctico: Creaci√≥n de Cuenta en Snowflake](01_creacion_cuenta_snowflake.md)**  

‚úÖ **Al completar este caso pr√°ctico, estar√°s listo para explorar Snowflake y empezar a trabajar con datos en la nube.**  

---

## Arquitectura de Snowflake

### Arquitectura de tres capas

![Arquitectura de tres capas en Snowflake](./resources/Imagen1.png)

*Figura: Diagrama de la arquitectura de tres capas en Snowflake, que incluye Cloud Services, Query Processing y Database Storage.*

#### 1. Service Layer (Cloud Services)
Esta capa es la encargada de **gestionar la seguridad, autenticaci√≥n y control de acceso en Snowflake**. Incluye funciones como la optimizaci√≥n de consultas, el manejo de metadatos y la integraci√≥n con herramientas externas de Business Intelligence (BI) y procesos de extracci√≥n, transformaci√≥n y carga (ETL). Adem√°s, administra la infraestructura subyacente de la plataforma en la nube, permitiendo que Snowflake se ofrezca como un servicio completamente gestionado.

#### 2. Compute Layer (Query Processing)  
El procesamiento de consultas en Snowflake se realiza a trav√©s de los **Virtual Warehouses**. Estas instancias de c√≥mputo operan de manera independiente, lo que permite ejecutar m√∫ltiples cargas de trabajo simult√°neamente sin interferencias. Snowflake permite escalar los warehouses de forma autom√°tica tanto horizontal como verticalmente, asegurando un rendimiento √≥ptimo seg√∫n la demanda. Esta independencia evita problemas de concurrencia y permite una ejecuci√≥n eficiente de consultas sobre grandes vol√∫menes de datos.

#### 3. Storage Layer (Database Storage)  
La capa de almacenamiento en Snowflake est√° dise√±ada para ser altamente escalable y segura. Utiliza un modelo de almacenamiento en formato columnar optimizado, lo que mejora la compresi√≥n y la eficiencia en la consulta de datos. Los datos almacenados en Snowflake est√°n distribuidos autom√°ticamente en m√∫ltiples regiones de la nube y pueden residir en proveedores como AWS, Azure o Google Cloud Platform. Adem√°s, Snowflake implementa **t√©cnicas avanzadas de compresi√≥n** y **cifrado autom√°tico**, garantizando la seguridad y el rendimiento de los datos almacenados.  

Un aspecto clave de esta capa es la capacidad de **pruning inteligente**, que permite minimizar la cantidad de datos escaneados en consultas, optimizando el rendimiento sin necesidad de intervenci√≥n manual.

![Ejemplo de Pruning Inteligente en Snowflake](./resources/Imagen2.png)

*Figura: Ejemplo de pruning inteligente en Snowflake, donde se minimiza la cantidad de datos escaneados al optimizar el acceso a micro-particiones.*

## Comparaci√≥n entre bases de datos por filas y por columnas  

Las bases de datos pueden organizar su informaci√≥n de diferentes maneras seg√∫n su prop√≥sito. En esta tabla se comparan las bases de datos orientadas a filas y a columnas en funci√≥n de su estructura, recuperaci√≥n de datos, tipos de operaci√≥n y ejemplos de cada una.  

- **Bases de datos por filas**: Optimizadas para transacciones r√°pidas, donde los registros completos suelen recuperarse con frecuencia. Son ideales para sistemas **OLTP** (Procesamiento de Transacciones en L√≠nea).  
  - **Ejemplos**: *Postgres*, MySQL, Oracle, SQL Server.  

- **Bases de datos por columnas**: Dise√±adas para an√°lisis de grandes vol√∫menes de datos, ya que permiten escanear solo las columnas necesarias en lugar de registros completos. Son ideales para entornos **OLAP** (Procesamiento Anal√≠tico en L√≠nea).  
  - **Ejemplos**: Snowflake, Amazon *Redshift*, *BigQuery*.  

Este modelo de almacenamiento impacta directamente en el rendimiento y eficiencia de las consultas dependiendo del tipo de carga de trabajo que se maneje.


| Categor√≠a              | Filas                          | Columnas                          |
|------------------------|------------------------------|-----------------------------------|
| Organizaci√≥n de datos  | Por filas                     | Por columnas                     |
| Recuperaci√≥n de datos  | Registros completos          | Columnas relevantes              |
| Tipos de operaci√≥n     | Transaccionales              | Anal√≠ticas                       |
| Ejemplos               | *Postgres*, MySQL, Oracle, SQL Server | Snowflake, Amazon *Redshift*, *BigQuery* |



### Arquitectura Multi-Cluster, Shared-Disk

Snowflake implementa un modelo de arquitectura h√≠brido que combina elementos de **shared-disk** y **shared-nothing**. Esta combinaci√≥n permite aprovechar lo mejor de ambos enfoques: la facilidad de administraci√≥n del almacenamiento compartido y la eficiencia del procesamiento distribuido.

#### Modelo de almacenamiento centralizado  
A diferencia de las bases de datos tradicionales de procesamiento distribuido, Snowflake utiliza un **repositorio de almacenamiento centralizado** donde todos los nodos pueden acceder a los datos. Este enfoque elimina la necesidad de replicar datos entre nodos, lo que simplifica la gesti√≥n del almacenamiento y permite un acceso m√°s eficiente a la informaci√≥n sin afectar el rendimiento.

#### Procesamiento distribuido mediante Virtual Warehouses  
El c√≥mputo en Snowflake se lleva a cabo mediante **cl√∫steres de warehouses virtuales**, donde cada nodo dentro del cl√∫ster procesa diferentes porciones de los datos de forma independiente. Gracias a este modelo, es posible ejecutar m√∫ltiples consultas en paralelo sin que unas interfieran con otras. Adem√°s, Snowflake permite escalar din√°micamente los warehouses, agregando m√°s recursos cuando la demanda aumenta y reduci√©ndolos cuando no se necesitan.

#### Escalabilidad y concurrencia optimizadas  
Uno de los mayores beneficios de esta arquitectura es su capacidad de **escalar horizontalmente** de forma autom√°tica y sin interrupciones. Si un alto volumen de usuarios o consultas genera carga en el sistema, Snowflake puede desplegar nodos adicionales para equilibrar la carga y mejorar el tiempo de respuesta. Esta escalabilidad evita los bloqueos y problemas de concurrencia t√≠picos de las bases de datos tradicionales.

Gracias a este enfoque h√≠brido, Snowflake logra combinar una administraci√≥n sencilla con alto rendimiento y escalabilidad, adapt√°ndose tanto a cargas de trabajo anal√≠ticas como a grandes vol√∫menes de procesamiento de datos en tiempo real.

![Comparaci√≥n entre arquitectura Shared-Disk y Shared-Nothing](./resources/Imagen3.png)

*Figura: Comparaci√≥n entre la arquitectura Shared-Disk y Shared-Nothing. En la arquitectura Shared-Disk, m√∫ltiples nodos comparten el mismo almacenamiento, mientras que en la arquitectura Shared-Nothing, cada nodo tiene su propio almacenamiento independiente, permitiendo un procesamiento distribuido m√°s eficiente.*


## Conexi√≥n a Snowflake

### Ecosistema de Snowflake

A trav√©s de una red extensiva de conectores, drivers , lenguajes de programaci√≥n, y utilidades, incluyendo:

- Partners certificados que proveen soluciones on-premise o en la nube para conectarse a Snowflake

- Otras herramientas y tecnolog√≠as tercerizadas que son conocidas para trabajar con Snowflake

- Clientes de Snowflake, incluyendo SnowSQL (_command line interface_), conectores para Python y Spark, y drivers para Node.js, JDBC, ODBC, y m√°s.

>‚ÑπÔ∏è **Info**: Snowflake trabaja con una amplia variedad de herramientas y tecnolog√≠as lideres en la industria.

![](./resources/01-image_4.png)

- Data Integration. ETL

- Business Intelligence

- Machine Learning and Data Science

- Security and Governance

- SQL Development and Management

- Native Programmatic Interfaces

- Snowflake Partner Connect

### Snowsight: The Snowflake web interface

Snowsight es el nombre de la interfaz gr√°fica en Snowflake y provee una experiencia unificada para trabajar con sus datos de Snowflake utilizando SQL o Python:

- Queries de SQL

- ML workflows utilizando notebooks de Snowflake

- An√°lisis de datos con Snowflake Copilot

- Snowpark Python

- Monitoreo de desempe√±o de queries e historia.

- Visualizaci√≥n

- Desarrollar y compartir Snowflake Native Apps

- Snowflake Marketplace

>‚ÑπÔ∏è **Info**: Snowflake resume el potente soporte SQL de Snowflake en una experiencia unificada y f√°cil de usar, importante para operaciones cr√≠ticas de Snowflake.


Desde esta interfaz tambi√©n podremos realizar operaciones y gestiones de administraci√≥n de la plataforma:

- Administraci√≥n de costos.

- Riesgos de seguridad, monitoreo y evaluaci√≥n

- Monitoreo de la carga de datos

- Creaci√≥n y administraci√≥n de usuarios

- Creaci√≥n y administraci√≥n de roles.

- Etc, etc, etc.

### SnowSQL (CLI Client)

SnowSQL es una herramienta poderosa y flexible para interactuar con Snowflake, proporcionando una interfaz de l√≠nea de comandos robusta para la ejecuci√≥n de consultas, administraci√≥n de bases de datos y manipulaci√≥n de datos, todo ello con un enfoque en la seguridad y la eficiencia.

Permite a los usuarios ejecutar consultas SQL, scripts y comandos de administraci√≥n directamente desde su terminal o l√≠nea de comandos.

Est√° dise√±ado para interactuar con el entorno de Snowflake, facilitando tareas como la ejecuci√≥n de consultas, la carga y descarga de datos, y la administraci√≥n de bases de datos y objetos de almacenamiento.

>‚ÑπÔ∏è **Info**: SnowSQL es el cliente de l√≠nea de comandos para conectarse a Snowflake y ejecutar consultas SQL y realizar todas las operaciones DDL y DML, incluida la carga y descarga de datos de las tablas de la base de datos.

## Caso pr√°ctico: Uso de SnowSQL para la gesti√≥n de datos

En este caso pr√°ctico, exploraremos SnowSQL, la interfaz de l√≠nea de comandos (CLI) de Snowflake, y aprenderemos a utilizarlo para ejecutar consultas y administrar datos en Snowflake.

### Objetivos del caso pr√°ctico  
- Instalar y configurar **SnowSQL** en tu equipo.  
- Conectarse a una cuenta de **Snowflake** mediante SnowSQL.  
- Ejecutar consultas SQL para la gesti√≥n de datos.  
- Cargar y descargar datos en Snowflake desde la l√≠nea de comandos.  

Para comenzar, sigue las instrucciones detalladas en el siguiente documento:  

üìÑ **[Caso Pr√°ctico: Uso de SnowSQL](01_snowsql.md)**  

‚úÖ **Al completar este caso pr√°ctico, ser√°s capaz de manejar Snowflake desde la l√≠nea de comandos.**


### Snowflake Extension for Visual Studio Code

Snowflake proporciona una extensi√≥n para Visual Studio Code (VS Code) que permite a los usuarios de Snowflake escribir y ejecutar sentencias SQL de Snowflake directamente en VS Code. La extensi√≥n tambi√©n se integra con Snowpark Python para proporcionar funciones de depuraci√≥n, resaltado de sintaxis y autocompletado para SQL en c√≥digo Python.

Las extensiones son funcionalidades preempaquetadas, a menudo proporcionadas por terceros, que a√±aden nuevas caracter√≠sticas y funcionalidades a VS Code.

>‚ÑπÔ∏è **Info**: Utilice la extensi√≥n Snowflake para Visual Studio Code para conectarse a Snowflake dentro de Visual Studio Code y realizar operaciones SQL.

#### Caso pr√°ctico: Conexi√≥n de Snowflake con VSC

Este caso pr√°ctico te guiar√° en la instalaci√≥n y configuraci√≥n de la extensi√≥n de Snowflake en Visual Studio Code, permiti√©ndote conectarte a tu cuenta de Snowflake y ejecutar consultas SQL directamente desde el editor

üìÑ **[Caso pr√°ctico: Conexi√≥n de Snowflake con VSC](01_conexion_vs.md)**

---

## Virtual Warehouse

Un **Virtual Warehouse**, o simplemente **warehouse**, es un cl√∫ster de recursos inform√°ticos que proporciona Snowflake para ejecutar operaciones como consultas, cargas de datos y transformaciones. Es un componente fundamental del modelo de computaci√≥n escalable de Snowflake.

### Funciones del Warehouse

Un warehouse proporciona recursos como CPU, memoria y almacenamiento temporal para realizar las siguientes operaciones:

- **Consultas SQL** (`SELECT`) que requieren procesamiento.
- **Operaciones DML**:
  - Inserciones, actualizaciones o eliminaciones de datos (`INSERT`, `UPDATE`, `DELETE`).
  - Carga de datos (`COPY INTO <tabla>`).
  - Exportaci√≥n de datos (`COPY INTO <ubicaci√≥n>`).

Para que estas operaciones se ejecuten, el warehouse debe estar en ejecuci√≥n y vinculado a la sesi√≥n activa.

### Sintaxis para la gesti√≥n de un Warehouse
#### Creaci√≥n de un Warehouse

La sintaxis b√°sica para crear un Virtual Warehouse en Snowflake y definir su tama√±o es la siguiente:

```sql
CREATE WAREHOUSE WH_DEMO
WITH WAREHOUSE_SIZE = 'MEDIUM';
```

En este ejemplo, se crea un warehouse llamado `WH_DEMO` con un tama√±o de `MEDIUM`. Puedes ajustar el tama√±o seg√∫n las necesidades de tu carga de trabajo seleccionando entre los tama√±os disponibles como `X-Small`, `Small`, `Large`, etc.

Adem√°s, es posible configurar **par√°metros adicionales** para automatizar su uso, como la suspensi√≥n autom√°tica por inactividad o la reanudaci√≥n autom√°tica al recibir una consulta. 
En la siguiente tabla, se presenta una lista m√°s detallada con algunos de los par√°metros de configuraci√≥n principales:

| Par√°metro                              | Descripci√≥n                                                                                     | Valores posibles                          | Valor por defecto |
|----------------------------------------|-------------------------------------------------------------------------------------------------|-------------------------------------------|-------------------|
| `WAREHOUSE_TYPE`                       | Especifica el tipo de warehouse.                                                                | `STANDARD`, `SNOWPARK-OPTIMIZED`          | `STANDARD`        |
| `WAREHOUSE_SIZE`                       | Define el tama√±o del warehouse, que determina la cantidad de recursos computacionales asignados.| `X-Small`, `Small`, `Medium`, `Large`, etc.| `Small`           |
| `AUTO_SUSPEND`                         | Tiempo (en segundos) de inactividad tras el cual el warehouse se suspende autom√°ticamente.      | N√∫mero entero (en segundos) o `NULL`      | 600 (10 minutos)  |
| `AUTO_RESUME`                          | Habilita o deshabilita la reactivaci√≥n autom√°tica del warehouse al recibir una consulta.        | `TRUE`, `FALSE`                           | `TRUE`            |
| `INITIALLY_SUSPENDED`                  | Indica si el warehouse debe crearse en estado suspendido.                                       | `TRUE`, `FALSE`                           | `FALSE`           |
| `MIN_CLUSTER_COUNT`                    | N√∫mero m√≠nimo de cl√∫steres activos en un warehouse multi-cluster.                               | N√∫mero entero                             | 1                 |
| `MAX_CLUSTER_COUNT`                    | N√∫mero m√°ximo de cl√∫steres que el warehouse puede escalar autom√°ticamente.                      | N√∫mero entero                             | 1                 |
| `SCALING_POLICY`                       | Define la pol√≠tica de escalado para warehouses multi-cluster.                                   | `STANDARD`, `ECONOMY`                     | `STANDARD`        |
| `ENABLE_QUERY_ACCELERATION`           | Activa o desactiva la aceleraci√≥n de consultas para mejorar el rendimiento.                     | `TRUE`, `FALSE`                           | `FALSE`           |
| `STATEMENT_QUEUED_TIMEOUT_IN_SECONDS` | Tiempo m√°ximo que una consulta puede permanecer en cola antes de ser cancelada.                 | N√∫mero entero (en segundos)               | 0 (sin l√≠mite)    |
| `STATEMENT_TIMEOUT_IN_SECONDS`        | Tiempo m√°ximo permitido para la ejecuci√≥n de una consulta antes de ser cancelada.               | N√∫mero entero (en segundos)               | 0 (sin l√≠mite)    |
| `RESOURCE_MONITOR`                     | Asocia un monitor de recursos para controlar el consumo de cr√©ditos del warehouse.              | Nombre de un monitor de recursos          | `NULL`            |


#### Ejemplo de configuraci√≥n avanzada

A continuaci√≥n, se muestra un ejemplo de c√≥mo configurar un warehouse con varios de estos par√°metros:

```sql
CREATE WAREHOUSE WH_ADVANCED
WITH WAREHOUSE_SIZE = 'LARGE'
  AUTO_SUSPEND = 300
  AUTO_RESUME = TRUE
  MIN_CLUSTER_COUNT = 2
  MAX_CLUSTER_COUNT = 5
  SCALING_POLICY = 'ECONOMY'
  STATEMENT_TIMEOUT_IN_SECONDS = 3600
  RESOURCE_MONITOR = 'MONITOR_WH';
```

En este ejemplo:
- Se crea un warehouse de tama√±o `LARGE`.
- Se suspende autom√°ticamente tras 5 minutos de inactividad (`AUTO_SUSPEND = 300`).
- Se reactiva autom√°ticamente al recibir una consulta (`AUTO_RESUME = TRUE`).
- Puede escalar entre 2 y 5 cl√∫steres seg√∫n la carga concurrente.
- Utiliza la pol√≠tica de escalado `ECONOMY` para priorizar el ahorro de costos.
- Las consultas tienen un tiempo m√°ximo de ejecuci√≥n de 1 hora (`STATEMENT_TIMEOUT_IN_SECONDS = 3600`).
- Se asocia un monitor de recursos llamado `MONITOR_WH` para controlar el consumo de cr√©ditos.

> ‚ÑπÔ∏è **Nota**: Configurar estos par√°metros adecuadamente puede optimizar el rendimiento y los costos de los warehouses en Snowflake, adapt√°ndolos a las necesidades espec√≠ficas de cada entorno.

#### Modificaci√≥n y gesti√≥n de un Warehouse

Una vez creado, puedes modificar las propiedades de un warehouse usando el comando `ALTER WAREHOUSE`. Algunos ejemplos comunes:

```sql
ALTER WAREHOUSE WH_ENGINEERING SET WAREHOUSE_SIZE = 'MEDIUM';
```

Este comando cambia el tama√±o del warehouse `WH_ENGINEERING` a `MEDIUM`.

```sql
ALTER WAREHOUSE WH_DATASCIENCE SET AUTO_SUSPEND = 120;
```

Este comando configura el warehouse `WH_DATASCIENCE` para que se suspenda autom√°ticamente tras 120 segundos de inactividad.

```sql
ALTER WAREHOUSE WH_ANALYTICS SUSPEND;
```

Este comando suspende manualmente el warehouse `WH_ANALYTICS`, liberando los recursos computacionales.

```sql
ALTER WAREHOUSE WH_ANALYTICS RESUME;
```

Este comando inicia manualmente el warehouse `WH_ANALYTICS`.

```sql
SELECT CURRENT_WAREHOUSE();
```

Con este comando SQL se obtiene la informaci√≥n del warehouse iniciado y en uso.

#### Eliminaci√≥n de un Warehouse

Para eliminar un Virtual Warehouse que ya no necesitas, puedes usar el siguiente comando:

```sql
DROP WAREHOUSE WH_DEMO;
```

Este comando elimina el warehouse `WH_DEMO` permanentemente. Aseg√∫rate de que el warehouse no est√© en uso antes de ejecutarlo.


### Tipos de Virtual Warehouse

Snowflake permite crear warehouses adaptados al tipo de carga de trabajo mediante el par√°metro `WAREHOUSE_TYPE`. Existen dos tipos principales:

- **STANDARD** (por defecto): Adecuado para la mayor√≠a de cargas de trabajo, como consultas SQL, cargas de datos, operaciones DML, etc.
- **SNOWPARK-OPTIMIZED**: Dise√±ado para ejecutar c√≥digo en **Snowpark**, ofreciendo recursos adicionales ideales para flujos de trabajo avanzados de **machine learning**, procesamiento distribuido y ejecuci√≥n de c√≥digo en Python o Java dentro de Snowflake.

#### Ejemplo: Crear un warehouse optimizado para Snowpark

```sql
CREATE WAREHOUSE WH_SPARK
WITH WAREHOUSE_SIZE = 'MEDIUM'
     WAREHOUSE_TYPE = 'SNOWPARK-OPTIMIZED'
```

> ‚ÑπÔ∏è Utiliza `SNOWPARK-OPTIMIZED` si vas a trabajar con Snowpark, notebooks o flujos de ciencia de datos directamente en Snowflake.




### Warehouse Size



El tama√±o de un warehouse determina la cantidad de recursos computacionales disponibles. Snowflake admite los siguientes tama√±os:

| Warehouse Size | Credits / Hour | Credits / Second | Notes |
| -------------- | -------------- | ---------------- | ----- |
| X-Small        | 1              | 0.0003           | Tama√±o por defecto en Snowsight |
| Small          | 2              | 0.0006           | |
| Medium         | 4              | 0.0011           | |
| Large          | 8              | 0.0022           | |
| X-Large        | 16             | 0.0044           | Creado en Classic Console |
| 2X-Large       | 32             | 0.0089           | |
| 3X-Large       | 64             | 0.0178           | |
| 4X-Large       | 128            | 0.0356           | |
| 5X-Large       | 256            | 0.0711           | Disponible en AWS y Azure |
| 6X-Large       | 512            | 0.1422           | Disponible en AWS y Azure |

El consumo de cr√©ditos se multiplica a medida que aumenta el tama√±o del warehouse. Snowflake factura por segundos con un m√≠nimo de 60 segundos por inicio.

| Running Time | Credits (X-Small) | Credits (X-Large) | Credits (5X-Large) |
| ------------ | ----------------- | ----------------- | ------------------ |
| 0-60 seconds | 0.017             | 0.267             | 4.268              |
| 61 seconds   | 0.017             | 0.271             | 4.336              |
| 2 minutes    | 0.033             | 0.533             | 8.532              |
| 10 minutes   | 0.167             | 2.667             | 42.668             |
| 1 hour       | 1.000             | 16.000            | 256.000            |



#### Configuraci√≥n de AUTO_SUSPEND

`AUTO_SUSPEND` define el tiempo (en segundos) que debe pasar sin actividad para que el warehouse se suspenda autom√°ticamente. Esto ayuda a ahorrar cr√©ditos cuando no se est√° utilizando.

```sql
CREATE WAREHOUSE WH_DEMO
WITH WAREHOUSE_SIZE = 'MEDIUM'
     AUTO_SUSPEND = 300; -- Suspender tras 5 minutos de inactividad
```

#### Configuraci√≥n de AUTO_RESUME

`AUTO_RESUME` permite que el warehouse se reactive autom√°ticamente al recibir una consulta, sin necesidad de intervenci√≥n manual.

```sql
CREATE WAREHOUSE WH_DEMO
WITH WAREHOUSE_SIZE = 'MEDIUM'
     AUTO_RESUME = TRUE;
```

Tambi√©n se pueden combinar ambas configuraciones junto con el tama√±o:

```sql
CREATE WAREHOUSE WH_DEMO
WITH WAREHOUSE_SIZE = 'MEDIUM'
     AUTO_SUSPEND = 300
     AUTO_RESUME = TRUE;
```

> ‚ÑπÔ∏è Mientras un WH est√© activo, consume **cr√©ditos Snowflake**, lo que hace importante optimizar su configuraci√≥n.

> ‚ÑπÔ∏è Consejo: Habilita `AUTO_SUSPEND` y `AUTO_RESUME` para evitar costos innecesarios por warehouses activos sin uso.



### Escalabilidad Autom√°tica con Multi-cluster

En Snowflake, un **Multi-cluster Warehouse** permite escalar autom√°ticamente horizontalmente (a√±adiendo m√°s cl√∫steres de c√≥mputo) para responder a picos de carga y mejorar la **concurrencia** sin degradar el rendimiento.

Esto es especialmente √∫til cuando m√∫ltiples usuarios o procesos est√°n ejecutando consultas al mismo tiempo, como sucede en entornos de BI o dashboards interactivos.

#### ¬øC√≥mo funciona?

Cuando un warehouse est√° configurado como **multi-cluster**, Snowflake puede iniciar autom√°ticamente **uno o m√°s cl√∫steres adicionales** para repartir la carga cuando hay muchas consultas simult√°neas encoladas.

Puedes definir:
- `MIN_CLUSTER_COUNT`: n√∫mero m√≠nimo de cl√∫steres activos.
- `MAX_CLUSTER_COUNT`: n√∫mero m√°ximo de cl√∫steres que Snowflake puede iniciar autom√°ticamente seg√∫n la demanda.

#### Ejemplo de creaci√≥n de un Warehouse con escalabilidad autom√°tica:

```sql
CREATE WAREHOUSE WH_DEMO
WITH WAREHOUSE_SIZE = 'MEDIUM'
     MIN_CLUSTER_COUNT = 1
     MAX_CLUSTER_COUNT = 3
     AUTO_SUSPEND = 300
     AUTO_RESUME = TRUE;
```

> üîÅ En este ejemplo, Snowflake comenzar√° con 1 cl√∫ster y podr√° escalar hasta 3 si detecta carga concurrente elevada.

---

#### Pol√≠tica de Escalado

Adem√°s del rango de cl√∫steres, puedes definir **c√≥mo** Snowflake decide cu√°ndo escalar mediante el par√°metro `SCALING_POLICY`:

- **STANDARD**:  
  - Escala r√°pidamente al detectar alta carga (cuando un cl√∫ster est√° al 100%).  
  - Prioriza el **rendimiento**.  
  - Puede generar un **mayor consumo de cr√©ditos**.

- **ECONOMY**:  
  - Escala m√°s lentamente o con mayor tolerancia a la carga.  
  - Prioriza el **ahorro de costos**.  
  - Puede generar **colas si la carga es alta**.

```sql
CREATE WAREHOUSE WH_DEMO
WITH SCALING_POLICY = 'ECONOMY';
```

> ‚ÑπÔ∏è Usa `STANDARD` para entornos cr√≠ticos donde el tiempo de respuesta es prioritario, y `ECONOMY` en entornos donde el ahorro de costes es m√°s importante que la velocidad.



### Impacto del Tama√±o del Warehouse y Recomendaciones por Tipo de Carga

El tama√±o del warehouse influye directamente en el rendimiento de las operaciones, pero **no siempre m√°s grande significa mejor**. La elecci√≥n debe basarse en el tipo de carga de trabajo:

#### Cargas de datos (ETL)
- **Tama√±o recomendado**: `Small` o `Medium`
- El rendimiento depende m√°s del n√∫mero y tama√±o de archivos que del tama√±o del warehouse
- Aumentar el tama√±o puede **no mejorar la velocidad**, pero s√≠ el coste

#### Consultas y dashboards (BI)
- **Tama√±o recomendado**: `Medium` o `Large`
- Para consultas simult√°neas o dashboards activos, se recomienda usar **multi-cluster** con escalabilidad autom√°tica
- **Consultas complejas** pueden beneficiarse de mayor tama√±o, pero **consultas simples** no necesariamente

#### Desarrollo y pruebas
- **Tama√±o recomendado**: `X-Small` o `Small`
- Ideal para cargas ligeras y entornos de bajo consumo
- Activar `AUTO_SUSPEND` y `AUTO_RESUME` para minimizar el gasto de cr√©ditos

#### Ciencia de datos / Snowpark
- **Tama√±o recomendado**: `Large` o superior
- Utilizar `WAREHOUSE_TYPE = 'SNOWPARK-OPTIMIZED'` para procesamiento con Python o Java
- Adecuado para tareas con alto uso de CPU y memoria


### Cach√© en el Warehouse

Snowflake utiliza mecanismos de cach√© para mejorar el rendimiento de las consultas. Mientras un warehouse est√° activo, **almacena en memoria los resultados y datos m√°s utilizados**, lo que reduce el acceso a disco y acelera la ejecuci√≥n de consultas repetidas.

![](./resources/01-image_8.png)

Sin embargo, hay que tener en cuenta que:

- La cach√© **se borra** cuando el warehouse se suspende o se ejecuta una operaci√≥n DML (`INSERT`, `UPDATE`, `DELETE`, etc.).
- Activar `AUTO_SUSPEND` con tiempos muy bajos puede impedir que se aproveche la cach√© de manera efectiva.

> ‚ö†Ô∏è **Recomendaci√≥n**: Ajusta los tiempos de suspensi√≥n autom√°tica para **equilibrar el ahorro de cr√©ditos y el aprovechamiento de la cach√©**, especialmente en entornos donde se repiten muchas consultas.

### Caso pr√°ctico: Creaci√≥n de Warehouses seg√∫n necesidades de cada rol

En este caso pr√°ctico, exploraremos SnowSQL, la interfaz de l√≠nea de comandos (CLI) de Snowflake, y aprenderemos a utilizarlo para ejecutar consultas y administrar datos en Snowflake.

#### Objetivos del caso pr√°ctico  
- Crear diferentes warehouses para distintos roles en la empresa.
- Configurar par√°metros adecuados para cada tipo de workload.
- Optimizar el rendimiento y el consumo de cr√©ditos en Snowflake.
- Consolidar conocimientos aprendidos.

Para comenzar, sigue las instrucciones detalladas en el siguiente documento:  

üìÑ **[Caso Pr√°ctico: Creaci√≥n de Warehouses seg√∫n necesidades de cada rol](01_creacion_warehouses.md)**  

‚úÖ **Al completar este caso pr√°ctico, ser√°s capaz de crear, modificar y gestionar warehouses en Snowflake.**


---

## Zero-Copy Cloning y Data Sharing en Snowflake

### ¬øQu√© es Zero-Copy Cloning?

**Zero-Copy Cloning** permite crear una copia de bases de datos, esquemas o tablas sin duplicar f√≠sicamente los datos. Las copias son instant√°neas y no consumen espacio adicional, ya que se referencian los mismos datos hasta que hay cambios (copy-on-write).

#### Ventajas
- Clonado instant√°neo de grandes vol√∫menes de datos.
- Ideal para entornos de desarrollo, testing o validaciones.
- No incrementa el coste de almacenamiento inmediatamente.
- Compatible con Time Travel.

#### Sintaxis para crear un clon:

```sql
CREATE OR REPLACE TABLE mi_tabla_clon CLONE mi_tabla_original;
CREATE OR REPLACE SCHEMA mi_esquema_clon CLONE mi_esquema;
CREATE OR REPLACE DATABASE mi_db_clon CLONE mi_db;
```


<p>


<hr style="border: none; border-top: 1.5px dashed #000; background-color: transparent;">

## Data Sharing en Snowflake

### ¬øQu√© es Data Sharing?

Snowflake permite **compartir datos entre cuentas** sin necesidad de moverlos ni copiarlos. Esta funcionalidad se conoce como **Data Sharing**, y garantiza acceso a datos en **tiempo real**, de forma **segura** y **eficiente**, sin duplicaci√≥n de almacenamiento.

> **Ventajas clave**:
- Acceso instant√°neo a los datos compartidos
- No se generan copias adicionales de los datos
- Acceso de solo lectura para garantizar la integridad
- Alta seguridad con permisos granulares
- Compatible con m√∫ltiples cuentas o partners


### Arquitectura del Data Sharing

- Un **proveedor** crea un `SHARE` y otorga acceso a bases de datos o tablas.
- Una **cuenta consumidora** accede a estos datos directamente, sin copiarlos.
- Las consultas se ejecutan en tiempo real desde la cuenta consumidora.

```text
Proveedor ‚Üí [SHARE] ‚Üí Cuenta consumidora (misma regi√≥n o con Snowgrid)
```

<hr style="border: none; border-top: 1.5px dashed #000; background-color: transparent;">


### M√©todos de Compartici√≥n de Datos

| M√©todo                    | Descripci√≥n                                                                 |
|---------------------------|-----------------------------------------------------------------------------|
| **Direct Data Sharing**   | Compartici√≥n entre cuentas Snowflake en la misma regi√≥n.                   |
| **Reader Accounts**       | Permite compartir datos con organizaciones **sin cuenta Snowflake**.       |
| **Snowflake Marketplace** | Plataforma para publicar y consumir datasets compartidos p√∫blicamente.     |
| **Cross-Cloud Sharing**   | Compartici√≥n entre regiones o nubes distintas mediante **Snowgrid**.       |

*Tabla con la comparaci√≥n de m√©todos de compartici√≥n de datos*

![](./resources/01-image_9.png)
*M√©todos de comparticion de datos en Snowflake*

> ‚ÑπÔ∏è **Snowgrid** es la tecnolog√≠a subyacente de Snowflake que permite la colaboraci√≥n y el intercambio de datos entre cuentas en diferentes regiones y nubes. Facilita el **Cross-Cloud Sharing**, asegurando que los datos se compartan de manera segura, eficiente y en tiempo real, independientemente de la ubicaci√≥n geogr√°fica o el proveedor de nube utilizado.

<hr style="border: none; border-top: 1.5px dashed #000; background-color: transparent;">

### Pasos para crear un Data Share

1. Crear el SHARE:

```sql
CREATE SHARE ventas_share;
```

2. Agregar una base de datos o tablas al SHARE:

```sql
GRANT USAGE ON DATABASE ventas_db TO SHARE ventas_share;
GRANT SELECT ON ALL TABLES IN SCHEMA ventas_db.public TO SHARE ventas_share;
```

3. Agregar una cuenta consumidora (que ya tenga Snowflake):

```sql
ALTER SHARE ventas_share ADD ACCOUNT = 'ACCOUNT_ID_CONSUMIDOR';
```

<hr style="border: none; border-top: 1.5px dashed #000; background-color: transparent;">

### Uso de Reader Accounts

Cuando el consumidor **no tiene una cuenta de Snowflake**, se puede crear un **Reader Account**, gestionado por el proveedor, para que acceda con permisos de solo lectura.

#### ¬øQu√© es un Reader Account?

- Es una cuenta administrada por el proveedor de datos.
- No requiere que el cliente tenga una suscripci√≥n activa a Snowflake.
- Ideal para compartir datos con partners, clientes o equipos externos.

#### Crear una cuenta Reader:

```sql
CREATE MANAGED ACCOUNT cliente_analytics
ADMIN_NAME = 'admin_user'
ADMIN_PASSWORD = 'SecurePassword123'
TYPE = READER;
```

> ‚ÑπÔ∏è Despu√©s de crear la cuenta, tambi√©n se debe agregar al SHARE como una cuenta consumidora.

```sql
ALTER SHARE ventas_share ADD ACCOUNT = 'ID_READER_ACCOUNT';
```

<hr style="border: none; border-top: 1.5px dashed #000; background-color: transparent;">

### Acceso a los datos compartidos desde la cuenta consumidora

Una vez configurado el SHARE, la cuenta consumidora puede:

1. Ver los shares disponibles:

```sql
SHOW SHARES;
```

2. Crear una base de datos a partir del SHARE:

```sql
CREATE DATABASE ventas_compartidas FROM SHARE proveedor_org.ventas_share;
```

3. Consultar los datos compartidos directamente:

```sql
SELECT * FROM ventas_compartidas.public.ventas;
```

<hr style="border: none; border-top: 1.5px dashed #000; background-color: transparent;">

### Beneficios del Data Sharing

- **Acceso en tiempo real** sin cargas manuales ni retrasos.
- **Sin duplicaci√≥n de datos**: una sola fuente de la verdad.
- **Colaboraci√≥n entre cuentas** y departamentos.
- **Escalabilidad** para m√∫ltiples consumidores.
- **Eficiencia de almacenamiento** y ahorro en costes.

<hr style="border: none; border-top: 1.5px dashed #000; background-color: transparent;">

### Caso pr√°ctico: Creaci√≥n y uso de Shares en Snowflake

En este caso pr√°ctico, exploraremos c√≥mo compartir datos entre cuentas de Snowflake utilizando la funcionalidad de **Shares**, incluyendo vistas seguras, permisos, y la creaci√≥n de cuentas Reader para organizaciones externas.

#### Objetivos del caso pr√°ctico  
- Crear y configurar objetos `SHARE` en Snowflake.
- Compartir vistas seguras entre diferentes cuentas Snowflake.
- Asignar permisos adecuados sobre bases de datos, esquemas y vistas.
- Simular la configuraci√≥n tanto del proveedor como del consumidor del Share.
- Crear cuentas *Reader* para compartir datos con empresas sin cuenta Snowflake.

Para comenzar, sigue las instrucciones detalladas en el siguiente documento:  

üìÑ **[Caso Pr√°ctico: Creaci√≥n y uso de Shares en Snowflake](01_creacion_shares.md)**  

‚úÖ **Al completar este caso pr√°ctico, ser√°s capaz de crear, compartir y auditar objetos `SHARE` para facilitar la colaboraci√≥n entre organizaciones en Snowflake.**

---

## Time Travel

### ¬øQu√© es Time Travel?

**Time Travel** permite consultar o restaurar datos en un punto anterior en el tiempo (hasta 90 d√≠as dependiendo de la edici√≥n de Snowflake). Es √∫til para deshacer eliminaciones accidentales, ver estados anteriores o clonar versiones anteriores.

#### Comandos para recuperar datos:

- Por timestamp:

```sql
SELECT * FROM my_table AT (TIMESTAMP => '2024-01-01 12:00:00');
```

- Por offset (segundos):

```sql
SELECT * FROM my_table AT (OFFSET => -3600); -- Retrocede 1 hora
```

- Por query ID:

```sql
SELECT * FROM my_table BEFORE (STATEMENT => 'query_id');
```

Para obtener el query ID se puede consultar la funci√≥n de tabla del sistema ``INFORMATION_SCHEMA.QUERY_HISTORY()`` y filtrar por ``query_text``:

```sql
SELECT
    query_id, query_text, start_time
FROM
    TABLE(INFORMATION_SCHEMA.QUERY_HISTORY())
WHERE
    query_text LIKE 'DELETE FROM my_table WHERE%';
```

#### Clonado con Time Travel
Tambi√©n se puede usar Time Travel junto al uso de clonado de objetos en Snowflake para clonear desde cualquier punto temporal con los m√©todos vistos.

```sql
-- Clonado de tabla mediante el uso de TIMESTAMP
CREATE TABLE mi_tabla_historica CLONE 
mi_tabla_original AT (TIMESTAMP => '2024-01-01 12:00:00');

-- Clonado de tabla mediante el uso de OFFSET
CREATE TABLE mi_tabla_hace_2_horas CLONE mi_tabla_original AT (OFFSET => -7200);

-- Clonado de tabla mediante el uso de QUERY ID
CREATE TABLE mi_tabla_post_query CLONE mi_tabla_original AT (STATEMENT => 'e1c3b1a8-0601-4b5a-0000-3d0000000000');

```

---

## Fail-safe en Snowflake

### ¬øQu√© es Fail-safe?

**Fail-safe** es un mecanismo de recuperaci√≥n de datos **despu√©s de que Time Travel ha expirado**. Est√° pensado para situaciones **cr√≠ticas o catastr√≥ficas**, como errores del sistema o desastres operativos.

> ‚ö†Ô∏è **Importante:** El usuario **no tiene acceso directo** al Fail-safe. La recuperaci√≥n requiere contactar con el soporte de Snowflake.



### Diferencias entre Time Travel y Fail-safe

| Caracter√≠stica       | **Time Travel**                                                | **Fail-safe**                                                            |
|----------------------|----------------------------------------------------------------|---------------------------------------------------------------------------|
| Acceso a los datos   | Usuario                                                        | Solo el **soporte de Snowflake**                                              |
| Tiempo de retenci√≥n  | **1 a 90 d√≠as** (seg√∫n edici√≥n)                                    | **7 d√≠as** adicionales despu√©s de Time Travel                                 |
| Recuperaci√≥n         | Instant√°nea, por el usuario                                    | Manual, mediante solicitud formal a soporte                               |
| Motivo de uso        | Ver cambios, restaurar versiones anteriores                    | Recuperaci√≥n ante fallos cr√≠ticos o cat√°strofes                           |
| Flexibilidad         | Total: consultar o restaurar f√°cilmente                        | Limitada: requiere intervenci√≥n externa                                   |
| Coste                | Almacenamiento adicional por versi√≥n retenida                  | Coste interno de Snowflake, no garantiza recuperaci√≥n inmediata           |

---

## Snowflake Caching

Snowflake implementa diferentes niveles de cach√© para optimizar el rendimiento de las consultas y reducir el uso de recursos. A continuaci√≥n, se describen los principales tipos de cach√©:

### 1. Query Result Cache

- Guarda los resultados de las consultas ejecutadas recientemente.
- Disponible durante 24 horas, siempre que los datos subyacentes no cambien.
- Reutiliza resultados para acelerar la ejecuci√≥n de consultas repetidas.

### 2. Metadata Cache

- Almacena informaci√≥n sobre objetos (como tablas, vistas, esquemas).
- Optimiza operaciones de planificaci√≥n de consultas evitando accesos innecesarios al almacenamiento.
- No se ve afectado por operaciones DML sobre los datos.

### 3. Virtual Warehouse Local Disk Cache

- Almacena micro-particiones en el almacenamiento local del warehouse virtual.
- Permite acceder r√°pidamente a datos que han sido le√≠dos recientemente.
- Mejora el rendimiento de las consultas que acceden repetidamente a los mismos datos.

---


